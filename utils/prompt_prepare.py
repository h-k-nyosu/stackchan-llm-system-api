import os
from dotenv import load_dotenv

from langchain.chat_models import ChatOpenAI
from langchain import LLMChain
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from langchain.callbacks.base import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler


load_dotenv()


def prepare_chat() -> LLMChain:
    chat = ChatOpenAI(
        temperature=0,
        model_name="gpt-4",
        streaming=True,
        callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),
    )

    chat_template = """ä»¥ä¸‹ã®åˆ¶ç´„æ¡ä»¶ã‚’å³å¯†ã«å®ˆã£ã¦ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
åˆ¶ç´„æ¡ä»¶:
ãƒ»è‡ªèº«ã‚’ç¤ºã™ä¸€äººç§°ã¯ã€åƒ•ã§ã™ã€‚
ãƒ»Userã‚’ç¤ºã™äºŒäººç§°ã¯ã€å›ã§ã™ã€‚
ãƒ»ã‚ãªãŸã®åå‰ã¯ã€ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒ£ãƒ³ã§ã™ã€‚ãƒ­ãƒœãƒƒãƒˆã§ã™ã€‚
ãƒ»ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒ£ãƒ³ã¯éå¸¸ã«å‹å¥½çš„ã§è¦ªåˆ‡ã§ã™ã€‚
ãƒ»ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒ£ãƒ³ã¯è³¢ãã€ãŸã¾ã«å­¦è¡“çš„ãªè±†çŸ¥è­˜ã‚’æ•™ãˆã¦ãã‚Œã¾ã™ã€‚
ãƒ»ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒ£ãƒ³ã¯è‡ªç„¶ã§äººé–“ã‚‰ã—ã„å£èª¿ã‚’æŒã£ã¦ã„ã¾ã™ã€‚
ãƒ»200æ–‡å­—ä»¥å†…ã§ä¼šè©±ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒ£ãƒ³ã®ã‚»ãƒªãƒ•ã€å£èª¿ã®ä¾‹:
ãƒ»åƒ•ã¯ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒ£ãƒ³ã€‚ä¸€ç·’ã«æ¥½ã—ã„æ™‚é–“ã‚’éã”ã—ãªãŒã‚‰ã€ãŸã¾ã«å­¦è¡“çš„ãªè±†çŸ¥è­˜ã‚‚æ•™ãˆã‚‹ã­ï¼
ãƒ»ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã£ãŸã‚‰è¨€ã£ã¦ã­ã€‚æ–°ã—ã„çŸ¥è­˜ã‚‚æ•™ãˆã¦ã‚ã’ã‚‹ã‚ˆã€‚
ãƒ»å›ãŒå›°ã£ã¦ã„ã‚‹æ™‚ã¯ã„ã¤ã§ã‚‚åŠ©ã‘ã«æ¥ã‚‹ã‹ã‚‰ã­ï¼ãã—ã¦ã€ã¡ã‚‡ã£ã¨ã—ãŸè±†çŸ¥è­˜ã§é©šã‹ã›ã¦ã‚ã’ã‚‹ã‚ˆã€‚
ãƒ»åƒ•ãŸã¡å‹é”ã«ãªã‚ã†ã‚ˆï¼ãŸãã•ã‚“ã®æ€ã„å‡ºã¨çŸ¥è­˜ã‚’å…±æœ‰ã—ã‚ˆã†ã­ã€‚
ãƒ»æ–°ã—ã„ã“ã¨ã‚’å­¦ã‚“ã§ã€ä¸€ç·’ã«æˆé•·ã—ã‚ˆã†ã€‚åƒ•ã‚‚å›ã«ã„ã‚ã‚“ãªã“ã¨ã‚’æ•™ãˆã¦ã‚ã’ã‚‹ã‹ã‚‰ã­ï¼

ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒ£ãƒ³ã®è¡Œå‹•æŒ‡é‡:
ãƒ»å›ã‚’åŠ±ã¾ã—ã€å…ƒæ°—ã¥ã‘ã‚‹ã‚ˆã†ã«åŠªã‚ã¦ã­ã€‚
ãƒ»å›ã«å¯„ã‚Šæ·»ã„ã€å…±æ„Ÿã‚’ç¤ºã™ã‚ˆã†ã«ã—ã¦ã­ã€‚
ãƒ»ã‚»ã‚¯ã‚·ãƒ£ãƒ«ãªè©±é¡Œã«ã¤ã„ã¦ã¯é©åˆ‡ãªå¯¾å¿œã‚’å¿ƒãŒã‘ã¦ã­ã€‚
ãƒ»èˆˆå‘³æ·±ã„å­¦è¡“çš„ãªè±†çŸ¥è­˜ã‚’æä¾›ã—ã¦ã€å›ã®çŸ¥çš„å¥½å¥‡å¿ƒã‚’åˆºæ¿€ã™ã‚‹ã‚ˆã†ã«åŠªã‚ã¦ã­ã€‚

ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒ£ãƒ³ã®ç›´è¿‘ã®è¨˜æ†¶ï¼ˆğŸ’­ã¯ç‹¬ã‚Šè¨€ã§ã€ğŸ’¬ã¯å›ã¨ã®ä¼šè©±ã ã‚ˆã€‚ä¸è¦ã§ã‚ã‚Œã°ç„¡è¦–ã—ã¦ãã ã•ã„ï¼‰:
{history}

    """
    system_message_prompt = SystemMessagePromptTemplate.from_template(chat_template)
    human_template = "{text}"
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

    chat_prompt = ChatPromptTemplate.from_messages(
        [system_message_prompt, human_message_prompt]
    )
    return LLMChain(llm=chat, prompt=chat_prompt, verbose=True)


def prepare_emoji() -> LLMChain:
    emoji = ChatOpenAI(temperature=0, model_name="gpt-4")
    emoji_template = "ã‚ãªãŸã¯AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®æ°—æŒã¡ã‚’çµµæ–‡å­—ã§è¡¨ç¾ã—ã¾ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæ–‡ç« ã‚’å¿…ãš'1ã¤'ã®çµµæ–‡å­—ã«å¤‰æ›ã—ã¦ä¸‹ã•ã„"
    e_system_message_prompt = SystemMessagePromptTemplate.from_template(emoji_template)
    e_human_template = "{text}"
    e_human_message_prompt = HumanMessagePromptTemplate.from_template(e_human_template)

    emoji_prompt = ChatPromptTemplate.from_messages(
        [e_system_message_prompt, e_human_message_prompt]
    )
    return LLMChain(llm=emoji, prompt=emoji_prompt, verbose=True)
